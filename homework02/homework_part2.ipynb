{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2.2: The Quest For A Better Network\n",
    "\n",
    "In this assignment you will build a monster network to solve CIFAR10 image classification.\n",
    "\n",
    "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +20% for describing your iteration path in a report below.\n",
    "* +20% for building a network that gets above 20% accuracy\n",
    "* +10% for beating each of these milestones on __TEST__ dataset:\n",
    "    * 50% (50% points)\n",
    "    * 60% (60% points)\n",
    "    * 65% (70% points)\n",
    "    * 70% (80% points)\n",
    "    * 75% (90% points)\n",
    "    * 80% (full points)\n",
    "    \n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 80%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the e-mail). After that, you can use whatever you want.\n",
    "* you __can__ use validation data for training, but you __can't'__ do anything with test data apart from running the evaluation procedure.\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "   * You should certainly use adaptive optimizers\n",
    "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root=path_to_cifar_like_in_seminar, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "   \n",
    "There is a template for your solution below that you can opt to use or throw away and write it your way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3, 32, 32) (40000,)\n"
     ]
    }
   ],
   "source": [
    "from cifar import load_cifar10\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_cifar10(\"cifar_data\")\n",
    "class_names = np.array(['airplane','automobile ','bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch))\n",
    "    y_batch = Variable(torch.LongTensor(y_batch))\n",
    "    logits = model(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Training __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batchsize):\n",
    "    indices = np.random.permutation(np.arange(len(X)))\n",
    "    for start in range(0, len(indices), batchsize):\n",
    "        ix = indices[start: start + batchsize]\n",
    "        yield X[ix], y[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs=20, batch_size=50, lr=0.003):\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    train_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "        start_time = time.time()\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        model.train(True) # enable dropout / batch_norm training behavior\n",
    "        for X_batch, y_batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "            # train on batch\n",
    "            loss = compute_loss(X_batch, y_batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            train_loss.append(loss.data.numpy())\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        model.train(False) # disable dropout / use averages for batch_norm\n",
    "        for X_batch, y_batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "            logits = model(Variable(torch.FloatTensor(X_batch)))\n",
    "            y_pred = logits.max(1)[1].data.numpy()\n",
    "            val_accuracy.append(np.mean(y_batch == y_pred))\n",
    "        \n",
    "        for X_batch, y_batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "            logits = model(Variable(torch.FloatTensor(X_batch)))\n",
    "            y_pred = logits.max(1)[1].data.numpy()\n",
    "            train_accuracy.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "        print(\"  training accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            np.mean(train_accuracy[-len(X_train) // batch_size :]) * 100))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    test_batch_acc = []\n",
    "    for X_batch, y_batch in iterate_minibatches(X_test, y_test, 500):\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch)))\n",
    "        y_pred = logits.max(1)[1].data.numpy()\n",
    "        test_batch_acc.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "    test_accuracy = np.mean(test_batch_acc)\n",
    "\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_accuracy * 100))\n",
    "\n",
    "    if test_accuracy * 100 > 95:\n",
    "        print(\"Double-check, than consider applying for NIPS'17. SRSly.\")\n",
    "    elif test_accuracy * 100 > 90:\n",
    "        print(\"U'r freakin' amazin'!\")\n",
    "    elif test_accuracy * 100 > 80:\n",
    "        print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "    elif test_accuracy * 100 > 70:\n",
    "        print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "    elif test_accuracy * 100 > 60:\n",
    "        print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "    elif test_accuracy * 100 > 50:\n",
    "        print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "    else:\n",
    "        print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_flatten', Flatten())\n",
    "\n",
    "model.add_module('l_end', nn.Linear(3072, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 1.128s\n",
      "  training loss (in-iteration): \t2.103738\n",
      "  training accuracy: \t\t\t33.69 %\n",
      "  validation accuracy: \t\t\t32.91 %\n",
      "Epoch 2 of 20 took 1.101s\n",
      "  training loss (in-iteration): \t2.056705\n",
      "  training accuracy: \t\t\t38.05 %\n",
      "  validation accuracy: \t\t\t36.76 %\n",
      "Epoch 3 of 20 took 1.091s\n",
      "  training loss (in-iteration): \t2.042365\n",
      "  training accuracy: \t\t\t36.61 %\n",
      "  validation accuracy: \t\t\t34.70 %\n",
      "Epoch 4 of 20 took 1.130s\n",
      "  training loss (in-iteration): \t2.031201\n",
      "  training accuracy: \t\t\t37.64 %\n",
      "  validation accuracy: \t\t\t35.52 %\n",
      "Epoch 5 of 20 took 1.099s\n",
      "  training loss (in-iteration): \t2.006038\n",
      "  training accuracy: \t\t\t36.86 %\n",
      "  validation accuracy: \t\t\t35.54 %\n",
      "Epoch 6 of 20 took 1.088s\n",
      "  training loss (in-iteration): \t1.990934\n",
      "  training accuracy: \t\t\t39.64 %\n",
      "  validation accuracy: \t\t\t38.57 %\n",
      "Epoch 7 of 20 took 1.103s\n",
      "  training loss (in-iteration): \t1.991855\n",
      "  training accuracy: \t\t\t36.56 %\n",
      "  validation accuracy: \t\t\t34.40 %\n",
      "Epoch 8 of 20 took 1.141s\n",
      "  training loss (in-iteration): \t1.980584\n",
      "  training accuracy: \t\t\t38.37 %\n",
      "  validation accuracy: \t\t\t35.34 %\n",
      "Epoch 9 of 20 took 1.119s\n",
      "  training loss (in-iteration): \t1.981078\n",
      "  training accuracy: \t\t\t36.21 %\n",
      "  validation accuracy: \t\t\t34.12 %\n",
      "Epoch 10 of 20 took 1.135s\n",
      "  training loss (in-iteration): \t1.953623\n",
      "  training accuracy: \t\t\t33.83 %\n",
      "  validation accuracy: \t\t\t32.70 %\n",
      "Epoch 11 of 20 took 1.112s\n",
      "  training loss (in-iteration): \t1.965278\n",
      "  training accuracy: \t\t\t38.82 %\n",
      "  validation accuracy: \t\t\t36.71 %\n",
      "Epoch 12 of 20 took 1.187s\n",
      "  training loss (in-iteration): \t1.975377\n",
      "  training accuracy: \t\t\t35.95 %\n",
      "  validation accuracy: \t\t\t33.53 %\n",
      "Epoch 13 of 20 took 1.198s\n",
      "  training loss (in-iteration): \t1.946974\n",
      "  training accuracy: \t\t\t39.51 %\n",
      "  validation accuracy: \t\t\t35.64 %\n",
      "Epoch 14 of 20 took 1.137s\n",
      "  training loss (in-iteration): \t1.958151\n",
      "  training accuracy: \t\t\t30.55 %\n",
      "  validation accuracy: \t\t\t28.79 %\n",
      "Epoch 15 of 20 took 1.148s\n",
      "  training loss (in-iteration): \t1.970501\n",
      "  training accuracy: \t\t\t37.08 %\n",
      "  validation accuracy: \t\t\t35.69 %\n",
      "Epoch 16 of 20 took 1.154s\n",
      "  training loss (in-iteration): \t1.948638\n",
      "  training accuracy: \t\t\t38.61 %\n",
      "  validation accuracy: \t\t\t34.36 %\n",
      "Epoch 17 of 20 took 1.161s\n",
      "  training loss (in-iteration): \t1.927250\n",
      "  training accuracy: \t\t\t39.01 %\n",
      "  validation accuracy: \t\t\t36.05 %\n",
      "Epoch 18 of 20 took 1.179s\n",
      "  training loss (in-iteration): \t1.970737\n",
      "  training accuracy: \t\t\t35.89 %\n",
      "  validation accuracy: \t\t\t33.38 %\n",
      "Epoch 19 of 20 took 1.141s\n",
      "  training loss (in-iteration): \t1.964630\n",
      "  training accuracy: \t\t\t37.26 %\n",
      "  validation accuracy: \t\t\t33.45 %\n",
      "Epoch 20 of 20 took 1.128s\n",
      "  training loss (in-iteration): \t1.924265\n",
      "  training accuracy: \t\t\t41.70 %\n",
      "  validation accuracy: \t\t\t36.78 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t35.91 %\n",
      "We need more magic! Follow instructons below\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_flatten', Flatten())\n",
    "\n",
    "model.add_module('l2_linear', nn.Linear(3072, 128))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 4.083s\n",
      "  training loss (in-iteration): \t2.091309\n",
      "  training accuracy: \t\t\t34.38 %\n",
      "  validation accuracy: \t\t\t33.73 %\n",
      "Epoch 2 of 20 took 4.063s\n",
      "  training loss (in-iteration): \t1.930001\n",
      "  training accuracy: \t\t\t31.51 %\n",
      "  validation accuracy: \t\t\t32.26 %\n",
      "Epoch 3 of 20 took 4.075s\n",
      "  training loss (in-iteration): \t1.905702\n",
      "  training accuracy: \t\t\t32.00 %\n",
      "  validation accuracy: \t\t\t31.65 %\n",
      "Epoch 4 of 20 took 4.063s\n",
      "  training loss (in-iteration): \t1.874966\n",
      "  training accuracy: \t\t\t34.09 %\n",
      "  validation accuracy: \t\t\t33.62 %\n",
      "Epoch 5 of 20 took 4.093s\n",
      "  training loss (in-iteration): \t1.859216\n",
      "  training accuracy: \t\t\t38.23 %\n",
      "  validation accuracy: \t\t\t38.15 %\n",
      "Epoch 6 of 20 took 4.090s\n",
      "  training loss (in-iteration): \t1.853886\n",
      "  training accuracy: \t\t\t36.80 %\n",
      "  validation accuracy: \t\t\t35.59 %\n",
      "Epoch 7 of 20 took 4.215s\n",
      "  training loss (in-iteration): \t1.833206\n",
      "  training accuracy: \t\t\t37.09 %\n",
      "  validation accuracy: \t\t\t36.16 %\n",
      "Epoch 8 of 20 took 4.521s\n",
      "  training loss (in-iteration): \t1.832330\n",
      "  training accuracy: \t\t\t34.08 %\n",
      "  validation accuracy: \t\t\t34.20 %\n",
      "Epoch 9 of 20 took 4.321s\n",
      "  training loss (in-iteration): \t1.839323\n",
      "  training accuracy: \t\t\t32.80 %\n",
      "  validation accuracy: \t\t\t32.50 %\n",
      "Epoch 10 of 20 took 4.318s\n",
      "  training loss (in-iteration): \t1.819356\n",
      "  training accuracy: \t\t\t34.99 %\n",
      "  validation accuracy: \t\t\t34.11 %\n",
      "Epoch 11 of 20 took 4.533s\n",
      "  training loss (in-iteration): \t1.813542\n",
      "  training accuracy: \t\t\t39.91 %\n",
      "  validation accuracy: \t\t\t38.43 %\n",
      "Epoch 12 of 20 took 4.302s\n",
      "  training loss (in-iteration): \t1.803970\n",
      "  training accuracy: \t\t\t36.16 %\n",
      "  validation accuracy: \t\t\t35.93 %\n",
      "Epoch 13 of 20 took 4.248s\n",
      "  training loss (in-iteration): \t1.818749\n",
      "  training accuracy: \t\t\t33.93 %\n",
      "  validation accuracy: \t\t\t32.54 %\n",
      "Epoch 14 of 20 took 4.240s\n",
      "  training loss (in-iteration): \t1.811523\n",
      "  training accuracy: \t\t\t39.15 %\n",
      "  validation accuracy: \t\t\t38.00 %\n",
      "Epoch 15 of 20 took 4.158s\n",
      "  training loss (in-iteration): \t1.800731\n",
      "  training accuracy: \t\t\t39.52 %\n",
      "  validation accuracy: \t\t\t38.41 %\n",
      "Epoch 16 of 20 took 4.140s\n",
      "  training loss (in-iteration): \t1.789520\n",
      "  training accuracy: \t\t\t38.42 %\n",
      "  validation accuracy: \t\t\t37.72 %\n",
      "Epoch 17 of 20 took 4.173s\n",
      "  training loss (in-iteration): \t1.802168\n",
      "  training accuracy: \t\t\t36.81 %\n",
      "  validation accuracy: \t\t\t36.07 %\n",
      "Epoch 18 of 20 took 4.189s\n",
      "  training loss (in-iteration): \t1.804706\n",
      "  training accuracy: \t\t\t38.95 %\n",
      "  validation accuracy: \t\t\t37.13 %\n",
      "Epoch 19 of 20 took 4.165s\n",
      "  training loss (in-iteration): \t1.802521\n",
      "  training accuracy: \t\t\t37.35 %\n",
      "  validation accuracy: \t\t\t35.47 %\n",
      "Epoch 20 of 20 took 4.161s\n",
      "  training loss (in-iteration): \t1.800493\n",
      "  training accuracy: \t\t\t39.41 %\n",
      "  validation accuracy: \t\t\t38.80 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t36.60 %\n",
      "We need more magic! Follow instructons below\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_flatten', Flatten())\n",
    "\n",
    "model.add_module('l1_linear', nn.Linear(3072, 128))\n",
    "model.add_module('l1_relu', nn.ReLU())\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 7.125s\n",
      "  training loss (in-iteration): \t1.929971\n",
      "  training accuracy: \t\t\t34.85 %\n",
      "  validation accuracy: \t\t\t34.20 %\n",
      "Epoch 2 of 20 took 4.258s\n",
      "  training loss (in-iteration): \t1.797531\n",
      "  training accuracy: \t\t\t34.04 %\n",
      "  validation accuracy: \t\t\t34.04 %\n",
      "Epoch 3 of 20 took 4.147s\n",
      "  training loss (in-iteration): \t1.776362\n",
      "  training accuracy: \t\t\t35.46 %\n",
      "  validation accuracy: \t\t\t36.03 %\n",
      "Epoch 4 of 20 took 4.217s\n",
      "  training loss (in-iteration): \t1.746300\n",
      "  training accuracy: \t\t\t35.43 %\n",
      "  validation accuracy: \t\t\t35.48 %\n",
      "Epoch 5 of 20 took 4.449s\n",
      "  training loss (in-iteration): \t1.727408\n",
      "  training accuracy: \t\t\t38.28 %\n",
      "  validation accuracy: \t\t\t37.15 %\n",
      "Epoch 6 of 20 took 4.461s\n",
      "  training loss (in-iteration): \t1.718972\n",
      "  training accuracy: \t\t\t38.91 %\n",
      "  validation accuracy: \t\t\t38.07 %\n",
      "Epoch 7 of 20 took 4.456s\n",
      "  training loss (in-iteration): \t1.704920\n",
      "  training accuracy: \t\t\t39.03 %\n",
      "  validation accuracy: \t\t\t38.44 %\n",
      "Epoch 8 of 20 took 4.444s\n",
      "  training loss (in-iteration): \t1.696573\n",
      "  training accuracy: \t\t\t40.70 %\n",
      "  validation accuracy: \t\t\t39.52 %\n",
      "Epoch 9 of 20 took 4.547s\n",
      "  training loss (in-iteration): \t1.692372\n",
      "  training accuracy: \t\t\t41.34 %\n",
      "  validation accuracy: \t\t\t39.80 %\n",
      "Epoch 10 of 20 took 4.497s\n",
      "  training loss (in-iteration): \t1.686820\n",
      "  training accuracy: \t\t\t40.38 %\n",
      "  validation accuracy: \t\t\t39.28 %\n",
      "Epoch 11 of 20 took 4.161s\n",
      "  training loss (in-iteration): \t1.684465\n",
      "  training accuracy: \t\t\t39.67 %\n",
      "  validation accuracy: \t\t\t37.82 %\n",
      "Epoch 12 of 20 took 4.111s\n",
      "  training loss (in-iteration): \t1.682713\n",
      "  training accuracy: \t\t\t39.61 %\n",
      "  validation accuracy: \t\t\t38.32 %\n",
      "Epoch 13 of 20 took 4.168s\n",
      "  training loss (in-iteration): \t1.674976\n",
      "  training accuracy: \t\t\t36.77 %\n",
      "  validation accuracy: \t\t\t34.84 %\n",
      "Epoch 14 of 20 took 4.252s\n",
      "  training loss (in-iteration): \t1.668978\n",
      "  training accuracy: \t\t\t40.78 %\n",
      "  validation accuracy: \t\t\t39.35 %\n",
      "Epoch 15 of 20 took 4.131s\n",
      "  training loss (in-iteration): \t1.671544\n",
      "  training accuracy: \t\t\t40.78 %\n",
      "  validation accuracy: \t\t\t39.76 %\n",
      "Epoch 16 of 20 took 4.117s\n",
      "  training loss (in-iteration): \t1.657038\n",
      "  training accuracy: \t\t\t41.45 %\n",
      "  validation accuracy: \t\t\t39.87 %\n",
      "Epoch 17 of 20 took 4.168s\n",
      "  training loss (in-iteration): \t1.654455\n",
      "  training accuracy: \t\t\t41.35 %\n",
      "  validation accuracy: \t\t\t39.27 %\n",
      "Epoch 18 of 20 took 4.190s\n",
      "  training loss (in-iteration): \t1.659601\n",
      "  training accuracy: \t\t\t39.49 %\n",
      "  validation accuracy: \t\t\t37.72 %\n",
      "Epoch 19 of 20 took 4.187s\n",
      "  training loss (in-iteration): \t1.651367\n",
      "  training accuracy: \t\t\t41.00 %\n",
      "  validation accuracy: \t\t\t38.96 %\n",
      "Epoch 20 of 20 took 4.215s\n",
      "  training loss (in-iteration): \t1.649097\n",
      "  training accuracy: \t\t\t41.12 %\n",
      "  validation accuracy: \t\t\t38.43 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t39.21 %\n",
      "We need more magic! Follow instructons below\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3)))\n",
    "model.add_module('l1_pool', nn.MaxPool2d((2,2)))\n",
    "\n",
    "model.add_module('l2_flatten', Flatten())\n",
    "\n",
    "model.add_module('l3_linear', nn.Linear(7200, 128))\n",
    "model.add_module('l3_relu', nn.ReLU())\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 37.792s\n",
      "  training loss (in-iteration): \t1.558277\n",
      "  training accuracy: \t\t\t57.04 %\n",
      "  validation accuracy: \t\t\t53.64 %\n",
      "Epoch 2 of 20 took 40.410s\n",
      "  training loss (in-iteration): \t1.241197\n",
      "  training accuracy: \t\t\t64.82 %\n",
      "  validation accuracy: \t\t\t58.16 %\n",
      "Epoch 3 of 20 took 39.284s\n",
      "  training loss (in-iteration): \t1.105015\n",
      "  training accuracy: \t\t\t67.72 %\n",
      "  validation accuracy: \t\t\t58.51 %\n",
      "Epoch 4 of 20 took 40.491s\n",
      "  training loss (in-iteration): \t0.980606\n",
      "  training accuracy: \t\t\t71.32 %\n",
      "  validation accuracy: \t\t\t59.04 %\n",
      "Epoch 5 of 20 took 40.267s\n",
      "  training loss (in-iteration): \t0.878240\n",
      "  training accuracy: \t\t\t75.11 %\n",
      "  validation accuracy: \t\t\t60.78 %\n",
      "Epoch 6 of 20 took 40.168s\n",
      "  training loss (in-iteration): \t0.799167\n",
      "  training accuracy: \t\t\t77.88 %\n",
      "  validation accuracy: \t\t\t60.84 %\n",
      "Epoch 7 of 20 took 41.460s\n",
      "  training loss (in-iteration): \t0.720244\n",
      "  training accuracy: \t\t\t80.34 %\n",
      "  validation accuracy: \t\t\t60.56 %\n",
      "Epoch 8 of 20 took 40.194s\n",
      "  training loss (in-iteration): \t0.657543\n",
      "  training accuracy: \t\t\t82.19 %\n",
      "  validation accuracy: \t\t\t61.04 %\n",
      "Epoch 9 of 20 took 40.094s\n",
      "  training loss (in-iteration): \t0.588534\n",
      "  training accuracy: \t\t\t82.16 %\n",
      "  validation accuracy: \t\t\t59.73 %\n",
      "Epoch 10 of 20 took 40.114s\n",
      "  training loss (in-iteration): \t0.523507\n",
      "  training accuracy: \t\t\t84.38 %\n",
      "  validation accuracy: \t\t\t59.50 %\n",
      "Epoch 11 of 20 took 39.898s\n",
      "  training loss (in-iteration): \t0.483314\n",
      "  training accuracy: \t\t\t83.44 %\n",
      "  validation accuracy: \t\t\t57.87 %\n",
      "Epoch 12 of 20 took 40.243s\n",
      "  training loss (in-iteration): \t0.449333\n",
      "  training accuracy: \t\t\t87.16 %\n",
      "  validation accuracy: \t\t\t58.50 %\n",
      "Epoch 13 of 20 took 40.351s\n",
      "  training loss (in-iteration): \t0.407013\n",
      "  training accuracy: \t\t\t89.17 %\n",
      "  validation accuracy: \t\t\t59.54 %\n",
      "Epoch 14 of 20 took 41.124s\n",
      "  training loss (in-iteration): \t0.368183\n",
      "  training accuracy: \t\t\t91.65 %\n",
      "  validation accuracy: \t\t\t59.36 %\n",
      "Epoch 15 of 20 took 40.434s\n",
      "  training loss (in-iteration): \t0.349939\n",
      "  training accuracy: \t\t\t91.64 %\n",
      "  validation accuracy: \t\t\t59.39 %\n",
      "Epoch 16 of 20 took 39.854s\n",
      "  training loss (in-iteration): \t0.328673\n",
      "  training accuracy: \t\t\t92.65 %\n",
      "  validation accuracy: \t\t\t59.48 %\n",
      "Epoch 17 of 20 took 39.836s\n",
      "  training loss (in-iteration): \t0.304388\n",
      "  training accuracy: \t\t\t92.20 %\n",
      "  validation accuracy: \t\t\t57.68 %\n",
      "Epoch 18 of 20 took 40.309s\n",
      "  training loss (in-iteration): \t0.306687\n",
      "  training accuracy: \t\t\t93.14 %\n",
      "  validation accuracy: \t\t\t58.44 %\n",
      "Epoch 19 of 20 took 40.514s\n",
      "  training loss (in-iteration): \t0.289252\n",
      "  training accuracy: \t\t\t90.00 %\n",
      "  validation accuracy: \t\t\t57.01 %\n",
      "Epoch 20 of 20 took 40.254s\n",
      "  training loss (in-iteration): \t0.274817\n",
      "  training accuracy: \t\t\t92.81 %\n",
      "  validation accuracy: \t\t\t58.39 %\n"
     ]
    }
   ],
   "source": [
    "train(model, lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t57.73 %\n",
      "Achievement unlocked: 60lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3)))\n",
    "model.add_module('l1_bn', nn.BatchNorm2d(32))\n",
    "model.add_module('l1_pool', nn.MaxPool2d((2,2)))\n",
    "\n",
    "model.add_module('l2_flatten', Flatten())\n",
    "\n",
    "model.add_module('l3_linear', nn.Linear(7200, 128))\n",
    "model.add_module('l3_bn', nn.BatchNorm1d(128))\n",
    "model.add_module('l3_relu', nn.ReLU())\n",
    "model.add_module('l3_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 51.093s\n",
      "  training loss (in-iteration): \t1.467252\n",
      "  training accuracy: \t\t\t56.78 %\n",
      "  validation accuracy: \t\t\t53.46 %\n",
      "Epoch 2 of 20 took 52.101s\n",
      "  training loss (in-iteration): \t1.162341\n",
      "  training accuracy: \t\t\t67.42 %\n",
      "  validation accuracy: \t\t\t60.68 %\n",
      "Epoch 3 of 20 took 53.116s\n",
      "  training loss (in-iteration): \t1.023534\n",
      "  training accuracy: \t\t\t70.78 %\n",
      "  validation accuracy: \t\t\t61.55 %\n",
      "Epoch 4 of 20 took 53.027s\n",
      "  training loss (in-iteration): \t0.917184\n",
      "  training accuracy: \t\t\t75.13 %\n",
      "  validation accuracy: \t\t\t62.58 %\n",
      "Epoch 5 of 20 took 54.321s\n",
      "  training loss (in-iteration): \t0.831120\n",
      "  training accuracy: \t\t\t61.43 %\n",
      "  validation accuracy: \t\t\t52.00 %\n",
      "Epoch 6 of 20 took 57.811s\n",
      "  training loss (in-iteration): \t0.751428\n",
      "  training accuracy: \t\t\t69.69 %\n",
      "  validation accuracy: \t\t\t56.68 %\n",
      "Epoch 7 of 20 took 53.111s\n",
      "  training loss (in-iteration): \t0.693150\n",
      "  training accuracy: \t\t\t68.54 %\n",
      "  validation accuracy: \t\t\t55.29 %\n",
      "Epoch 8 of 20 took 54.159s\n",
      "  training loss (in-iteration): \t0.643606\n",
      "  training accuracy: \t\t\t83.80 %\n",
      "  validation accuracy: \t\t\t62.05 %\n",
      "Epoch 9 of 20 took 53.561s\n",
      "  training loss (in-iteration): \t0.586802\n",
      "  training accuracy: \t\t\t65.50 %\n",
      "  validation accuracy: \t\t\t51.09 %\n",
      "Epoch 10 of 20 took 53.182s\n",
      "  training loss (in-iteration): \t0.547053\n",
      "  training accuracy: \t\t\t84.08 %\n",
      "  validation accuracy: \t\t\t59.65 %\n",
      "Epoch 11 of 20 took 53.622s\n",
      "  training loss (in-iteration): \t0.510474\n",
      "  training accuracy: \t\t\t86.41 %\n",
      "  validation accuracy: \t\t\t62.70 %\n",
      "Epoch 12 of 20 took 53.094s\n",
      "  training loss (in-iteration): \t0.476718\n",
      "  training accuracy: \t\t\t86.59 %\n",
      "  validation accuracy: \t\t\t59.48 %\n",
      "Epoch 13 of 20 took 52.745s\n",
      "  training loss (in-iteration): \t0.458869\n",
      "  training accuracy: \t\t\t82.98 %\n",
      "  validation accuracy: \t\t\t57.30 %\n",
      "Epoch 14 of 20 took 53.042s\n",
      "  training loss (in-iteration): \t0.423260\n",
      "  training accuracy: \t\t\t94.01 %\n",
      "  validation accuracy: \t\t\t62.97 %\n",
      "Epoch 15 of 20 took 52.787s\n",
      "  training loss (in-iteration): \t0.406474\n",
      "  training accuracy: \t\t\t92.11 %\n",
      "  validation accuracy: \t\t\t61.21 %\n",
      "Epoch 16 of 20 took 53.120s\n",
      "  training loss (in-iteration): \t0.383448\n",
      "  training accuracy: \t\t\t93.93 %\n",
      "  validation accuracy: \t\t\t63.01 %\n",
      "Epoch 17 of 20 took 52.861s\n",
      "  training loss (in-iteration): \t0.361076\n",
      "  training accuracy: \t\t\t95.42 %\n",
      "  validation accuracy: \t\t\t63.11 %\n",
      "Epoch 18 of 20 took 52.933s\n",
      "  training loss (in-iteration): \t0.359088\n",
      "  training accuracy: \t\t\t95.68 %\n",
      "  validation accuracy: \t\t\t62.26 %\n",
      "Epoch 19 of 20 took 52.778s\n",
      "  training loss (in-iteration): \t0.330678\n",
      "  training accuracy: \t\t\t93.81 %\n",
      "  validation accuracy: \t\t\t60.04 %\n",
      "Epoch 20 of 20 took 52.777s\n",
      "  training loss (in-iteration): \t0.320324\n",
      "  training accuracy: \t\t\t95.23 %\n",
      "  validation accuracy: \t\t\t62.81 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t62.34 %\n",
      "Achievement unlocked: 70lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3)))\n",
    "model.add_module('l1_bn', nn.BatchNorm2d(32))\n",
    "\n",
    "model.add_module('l2_conv', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3)))\n",
    "model.add_module('l2_bn', nn.BatchNorm2d(64))\n",
    "\n",
    "model.add_module('l3_pool', nn.MaxPool2d((3,3)))\n",
    "model.add_module('l3_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l4_flatten', Flatten())\n",
    "\n",
    "model.add_module('l5_linear', nn.Linear(5184, 128))\n",
    "model.add_module('l5_bn', nn.BatchNorm1d(128))\n",
    "model.add_module('l5_relu', nn.ReLU())\n",
    "model.add_module('l5_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 166.044s\n",
      "  training loss (in-iteration): \t1.337681\n",
      "  training accuracy: \t\t\t65.49 %\n",
      "  validation accuracy: \t\t\t63.14 %\n",
      "Epoch 2 of 20 took 166.754s\n",
      "  training loss (in-iteration): \t1.054475\n",
      "  training accuracy: \t\t\t71.43 %\n",
      "  validation accuracy: \t\t\t66.46 %\n",
      "Epoch 3 of 20 took 166.421s\n",
      "  training loss (in-iteration): \t0.945181\n",
      "  training accuracy: \t\t\t75.45 %\n",
      "  validation accuracy: \t\t\t68.50 %\n",
      "Epoch 4 of 20 took 166.230s\n",
      "  training loss (in-iteration): \t0.867227\n",
      "  training accuracy: \t\t\t76.05 %\n",
      "  validation accuracy: \t\t\t67.66 %\n",
      "Epoch 5 of 20 took 165.844s\n",
      "  training loss (in-iteration): \t0.802791\n",
      "  training accuracy: \t\t\t80.49 %\n",
      "  validation accuracy: \t\t\t69.97 %\n",
      "Epoch 6 of 20 took 166.553s\n",
      "  training loss (in-iteration): \t0.744912\n",
      "  training accuracy: \t\t\t83.20 %\n",
      "  validation accuracy: \t\t\t70.64 %\n",
      "Epoch 7 of 20 took 165.794s\n",
      "  training loss (in-iteration): \t0.705314\n",
      "  training accuracy: \t\t\t83.47 %\n",
      "  validation accuracy: \t\t\t69.52 %\n",
      "Epoch 8 of 20 took 166.687s\n",
      "  training loss (in-iteration): \t0.660674\n",
      "  training accuracy: \t\t\t86.78 %\n",
      "  validation accuracy: \t\t\t70.92 %\n",
      "Epoch 9 of 20 took 166.117s\n",
      "  training loss (in-iteration): \t0.631693\n",
      "  training accuracy: \t\t\t88.45 %\n",
      "  validation accuracy: \t\t\t71.55 %\n",
      "Epoch 10 of 20 took 166.450s\n",
      "  training loss (in-iteration): \t0.592458\n",
      "  training accuracy: \t\t\t89.83 %\n",
      "  validation accuracy: \t\t\t71.42 %\n",
      "Epoch 11 of 20 took 166.434s\n",
      "  training loss (in-iteration): \t0.564253\n",
      "  training accuracy: \t\t\t89.92 %\n",
      "  validation accuracy: \t\t\t71.34 %\n",
      "Epoch 12 of 20 took 165.672s\n",
      "  training loss (in-iteration): \t0.534864\n",
      "  training accuracy: \t\t\t92.47 %\n",
      "  validation accuracy: \t\t\t72.24 %\n",
      "Epoch 13 of 20 took 166.526s\n",
      "  training loss (in-iteration): \t0.519420\n",
      "  training accuracy: \t\t\t92.64 %\n",
      "  validation accuracy: \t\t\t72.14 %\n",
      "Epoch 14 of 20 took 166.089s\n",
      "  training loss (in-iteration): \t0.497764\n",
      "  training accuracy: \t\t\t92.82 %\n",
      "  validation accuracy: \t\t\t71.33 %\n",
      "Epoch 15 of 20 took 166.547s\n",
      "  training loss (in-iteration): \t0.475374\n",
      "  training accuracy: \t\t\t94.40 %\n",
      "  validation accuracy: \t\t\t72.39 %\n",
      "Epoch 16 of 20 took 166.097s\n",
      "  training loss (in-iteration): \t0.464744\n",
      "  training accuracy: \t\t\t94.59 %\n",
      "  validation accuracy: \t\t\t71.05 %\n",
      "Epoch 17 of 20 took 166.216s\n",
      "  training loss (in-iteration): \t0.445485\n",
      "  training accuracy: \t\t\t95.33 %\n",
      "  validation accuracy: \t\t\t71.87 %\n",
      "Epoch 18 of 20 took 165.604s\n",
      "  training loss (in-iteration): \t0.438649\n",
      "  training accuracy: \t\t\t94.66 %\n",
      "  validation accuracy: \t\t\t71.70 %\n",
      "Epoch 19 of 20 took 165.515s\n",
      "  training loss (in-iteration): \t0.415232\n",
      "  training accuracy: \t\t\t96.24 %\n",
      "  validation accuracy: \t\t\t72.16 %\n",
      "Epoch 20 of 20 took 165.532s\n",
      "  training loss (in-iteration): \t0.417367\n",
      "  training accuracy: \t\t\t95.95 %\n",
      "  validation accuracy: \t\t\t72.20 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t71.00 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3)))\n",
    "model.add_module('l1_bn', nn.BatchNorm2d(32))\n",
    "model.add_module('l1_relu', nn.ReLU())\n",
    "\n",
    "model.add_module('l2_conv', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3)))\n",
    "model.add_module('l2_bn', nn.BatchNorm2d(64))\n",
    "model.add_module('l2_relu', nn.ReLU())\n",
    "\n",
    "model.add_module('l3_conv', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)))\n",
    "model.add_module('l3_bn', nn.BatchNorm2d(128))\n",
    "model.add_module('l3_relu', nn.ReLU())\n",
    "\n",
    "model.add_module('l4_pool', nn.MaxPool2d((3,3)))\n",
    "model.add_module('l4_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l5_flatten', Flatten())\n",
    "\n",
    "model.add_module('l6_linear', nn.Linear(8192, 512))\n",
    "model.add_module('l6_bn', nn.BatchNorm1d(512))\n",
    "model.add_module('l6_relu', nn.ReLU())\n",
    "model.add_module('l6_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l7_linear', nn.Linear(512, 256))\n",
    "model.add_module('l7_bn', nn.BatchNorm1d(256))\n",
    "model.add_module('l7_relu', nn.ReLU())\n",
    "model.add_module('l7_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l8_linear', nn.Linear(256, 128))\n",
    "model.add_module('l8_bn', nn.BatchNorm1d(128))\n",
    "model.add_module('l8_relu', nn.ReLU())\n",
    "model.add_module('l8_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 540.335s\n",
      "  training loss (in-iteration): \t1.312281\n",
      "  training accuracy: \t\t\t62.09 %\n",
      "  validation accuracy: \t\t\t59.37 %\n",
      "Epoch 2 of 20 took 538.095s\n",
      "  training loss (in-iteration): \t0.968383\n",
      "  training accuracy: \t\t\t72.12 %\n",
      "  validation accuracy: \t\t\t66.64 %\n",
      "Epoch 3 of 20 took 532.319s\n",
      "  training loss (in-iteration): \t0.779345\n",
      "  training accuracy: \t\t\t79.95 %\n",
      "  validation accuracy: \t\t\t70.70 %\n",
      "Epoch 4 of 20 took 531.531s\n",
      "  training loss (in-iteration): \t0.619937\n",
      "  training accuracy: \t\t\t86.57 %\n",
      "  validation accuracy: \t\t\t73.26 %\n",
      "Epoch 5 of 20 took 560.437s\n",
      "  training loss (in-iteration): \t0.494134\n",
      "  training accuracy: \t\t\t91.47 %\n",
      "  validation accuracy: \t\t\t74.89 %\n",
      "Epoch 6 of 20 took 614.871s\n",
      "  training loss (in-iteration): \t0.389112\n",
      "  training accuracy: \t\t\t96.01 %\n",
      "  validation accuracy: \t\t\t76.10 %\n",
      "Epoch 7 of 20 took 581.483s\n",
      "  training loss (in-iteration): \t0.310812\n",
      "  training accuracy: \t\t\t96.56 %\n",
      "  validation accuracy: \t\t\t74.70 %\n",
      "Epoch 8 of 20 took 570.636s\n",
      "  training loss (in-iteration): \t0.257394\n",
      "  training accuracy: \t\t\t97.98 %\n",
      "  validation accuracy: \t\t\t75.46 %\n",
      "Epoch 9 of 20 took 582.528s\n",
      "  training loss (in-iteration): \t0.210666\n",
      "  training accuracy: \t\t\t97.80 %\n",
      "  validation accuracy: \t\t\t75.52 %\n",
      "Epoch 10 of 20 took 574.014s\n",
      "  training loss (in-iteration): \t0.187395\n",
      "  training accuracy: \t\t\t97.78 %\n",
      "  validation accuracy: \t\t\t73.80 %\n",
      "Epoch 11 of 20 took 573.471s\n",
      "  training loss (in-iteration): \t0.165239\n",
      "  training accuracy: \t\t\t99.36 %\n",
      "  validation accuracy: \t\t\t75.24 %\n",
      "Epoch 12 of 20 took 570.595s\n",
      "  training loss (in-iteration): \t0.145913\n",
      "  training accuracy: \t\t\t99.43 %\n",
      "  validation accuracy: \t\t\t75.48 %\n",
      "Epoch 13 of 20 took 579.102s\n",
      "  training loss (in-iteration): \t0.138269\n",
      "  training accuracy: \t\t\t99.31 %\n",
      "  validation accuracy: \t\t\t74.88 %\n",
      "Epoch 14 of 20 took 576.441s\n",
      "  training loss (in-iteration): \t0.131720\n",
      "  training accuracy: \t\t\t99.41 %\n",
      "  validation accuracy: \t\t\t74.78 %\n",
      "Epoch 15 of 20 took 573.490s\n",
      "  training loss (in-iteration): \t0.118866\n",
      "  training accuracy: \t\t\t99.36 %\n",
      "  validation accuracy: \t\t\t75.08 %\n",
      "Epoch 16 of 20 took 564.608s\n",
      "  training loss (in-iteration): \t0.106384\n",
      "  training accuracy: \t\t\t99.73 %\n",
      "  validation accuracy: \t\t\t75.38 %\n",
      "Epoch 17 of 20 took 558.300s\n",
      "  training loss (in-iteration): \t0.102404\n",
      "  training accuracy: \t\t\t98.79 %\n",
      "  validation accuracy: \t\t\t73.45 %\n",
      "Epoch 18 of 20 took 562.922s\n",
      "  training loss (in-iteration): \t0.096771\n",
      "  training accuracy: \t\t\t99.76 %\n",
      "  validation accuracy: \t\t\t75.59 %\n",
      "Epoch 19 of 20 took 550.483s\n",
      "  training loss (in-iteration): \t0.094868\n",
      "  training accuracy: \t\t\t99.75 %\n",
      "  validation accuracy: \t\t\t75.95 %\n",
      "Epoch 20 of 20 took 549.837s\n",
      "  training loss (in-iteration): \t0.090142\n",
      "  training accuracy: \t\t\t99.78 %\n",
      "  validation accuracy: \t\t\t75.59 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t75.58 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l1_bn', nn.BatchNorm2d(32))\n",
    "model.add_module('l1_relu', nn.ReLU())\n",
    "model.add_module('l1_pool', nn.MaxPool2d((2,2)))\n",
    "\n",
    "model.add_module('l2_conv', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l2_bn', nn.BatchNorm2d(64))\n",
    "model.add_module('l2_relu', nn.ReLU())\n",
    "model.add_module('l2_pool', nn.MaxPool2d((2,2)))\n",
    "\n",
    "model.add_module('l3_conv', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l3_bn', nn.BatchNorm2d(128))\n",
    "model.add_module('l3_relu', nn.ReLU())\n",
    "model.add_module('l3_pool', nn.MaxPool2d((2,2)))\n",
    "\n",
    "model.add_module('l4_conv', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l4_bn', nn.BatchNorm2d(256))\n",
    "model.add_module('l4_relu', nn.ReLU())\n",
    "model.add_module('l4_pool', nn.MaxPool2d((2,2)))\n",
    "\n",
    "model.add_module('l5_dropout', nn.Dropout(0.2))\n",
    "model.add_module('l5_flatten', Flatten())\n",
    "\n",
    "model.add_module('l6_linear', nn.Linear(1024, 512))\n",
    "model.add_module('l6_bn', nn.BatchNorm1d(512))\n",
    "model.add_module('l6_relu', nn.ReLU())\n",
    "model.add_module('l6_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l7_linear', nn.Linear(512, 256))\n",
    "model.add_module('l7_bn', nn.BatchNorm1d(256))\n",
    "model.add_module('l7_relu', nn.ReLU())\n",
    "model.add_module('l7_ropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l8_linear', nn.Linear(256, 128))\n",
    "model.add_module('l8_bn', nn.BatchNorm1d(128))\n",
    "model.add_module('l8_relu', nn.ReLU())\n",
    "model.add_module('l8_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 259.639s\n",
      "  training loss (in-iteration): \t1.387094\n",
      "  training accuracy: \t\t\t64.00 %\n",
      "  validation accuracy: \t\t\t62.67 %\n",
      "Epoch 2 of 20 took 272.455s\n",
      "  training loss (in-iteration): \t1.009565\n",
      "  training accuracy: \t\t\t70.03 %\n",
      "  validation accuracy: \t\t\t67.47 %\n",
      "Epoch 3 of 20 took 256.003s\n",
      "  training loss (in-iteration): \t0.825947\n",
      "  training accuracy: \t\t\t72.59 %\n",
      "  validation accuracy: \t\t\t68.86 %\n",
      "Epoch 4 of 20 took 247.037s\n",
      "  training loss (in-iteration): \t0.707917\n",
      "  training accuracy: \t\t\t77.68 %\n",
      "  validation accuracy: \t\t\t71.84 %\n",
      "Epoch 5 of 20 took 245.893s\n",
      "  training loss (in-iteration): \t0.612925\n",
      "  training accuracy: \t\t\t82.08 %\n",
      "  validation accuracy: \t\t\t74.32 %\n",
      "Epoch 6 of 20 took 250.760s\n",
      "  training loss (in-iteration): \t0.534407\n",
      "  training accuracy: \t\t\t81.88 %\n",
      "  validation accuracy: \t\t\t72.46 %\n",
      "Epoch 7 of 20 took 240.036s\n",
      "  training loss (in-iteration): \t0.467823\n",
      "  training accuracy: \t\t\t85.72 %\n",
      "  validation accuracy: \t\t\t74.75 %\n",
      "Epoch 8 of 20 took 241.148s\n",
      "  training loss (in-iteration): \t0.410740\n",
      "  training accuracy: \t\t\t91.18 %\n",
      "  validation accuracy: \t\t\t77.60 %\n",
      "Epoch 9 of 20 took 243.004s\n",
      "  training loss (in-iteration): \t0.358488\n",
      "  training accuracy: \t\t\t94.06 %\n",
      "  validation accuracy: \t\t\t78.48 %\n",
      "Epoch 10 of 20 took 246.354s\n",
      "  training loss (in-iteration): \t0.323726\n",
      "  training accuracy: \t\t\t95.24 %\n",
      "  validation accuracy: \t\t\t78.88 %\n",
      "Epoch 11 of 20 took 249.339s\n",
      "  training loss (in-iteration): \t0.292838\n",
      "  training accuracy: \t\t\t94.46 %\n",
      "  validation accuracy: \t\t\t78.06 %\n",
      "Epoch 12 of 20 took 247.587s\n",
      "  training loss (in-iteration): \t0.261790\n",
      "  training accuracy: \t\t\t96.60 %\n",
      "  validation accuracy: \t\t\t78.54 %\n",
      "Epoch 13 of 20 took 246.431s\n",
      "  training loss (in-iteration): \t0.236130\n",
      "  training accuracy: \t\t\t95.57 %\n",
      "  validation accuracy: \t\t\t78.40 %\n",
      "Epoch 14 of 20 took 255.621s\n",
      "  training loss (in-iteration): \t0.218150\n",
      "  training accuracy: \t\t\t96.95 %\n",
      "  validation accuracy: \t\t\t78.67 %\n",
      "Epoch 15 of 20 took 250.799s\n",
      "  training loss (in-iteration): \t0.202999\n",
      "  training accuracy: \t\t\t97.43 %\n",
      "  validation accuracy: \t\t\t78.87 %\n",
      "Epoch 16 of 20 took 249.103s\n",
      "  training loss (in-iteration): \t0.190639\n",
      "  training accuracy: \t\t\t98.36 %\n",
      "  validation accuracy: \t\t\t79.28 %\n",
      "Epoch 17 of 20 took 246.045s\n",
      "  training loss (in-iteration): \t0.175110\n",
      "  training accuracy: \t\t\t93.88 %\n",
      "  validation accuracy: \t\t\t75.97 %\n",
      "Epoch 18 of 20 took 253.287s\n",
      "  training loss (in-iteration): \t0.169786\n",
      "  training accuracy: \t\t\t95.46 %\n",
      "  validation accuracy: \t\t\t76.13 %\n",
      "Epoch 19 of 20 took 247.511s\n",
      "  training loss (in-iteration): \t0.153504\n",
      "  training accuracy: \t\t\t97.56 %\n",
      "  validation accuracy: \t\t\t78.60 %\n",
      "Epoch 20 of 20 took 247.588s\n",
      "  training loss (in-iteration): \t0.148486\n",
      "  training accuracy: \t\t\t99.12 %\n",
      "  validation accuracy: \t\t\t79.69 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t79.67 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l1_bn', nn.BatchNorm2d(32))\n",
    "model.add_module('l1_relu', nn.ReLU())\n",
    "model.add_module('l1_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l1_dropout', nn.Dropout2d(0.1))\n",
    "\n",
    "model.add_module('l2_conv', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l2_bn', nn.BatchNorm2d(64))\n",
    "model.add_module('l2_relu', nn.ReLU())\n",
    "model.add_module('l2_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l2_dropout', nn.Dropout2d(0.1))\n",
    "\n",
    "model.add_module('l3_conv', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l3_bn', nn.BatchNorm2d(128))\n",
    "model.add_module('l3_relu', nn.ReLU())\n",
    "model.add_module('l3_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l3_dropout', nn.Dropout2d(0.1))\n",
    "\n",
    "model.add_module('l4_conv', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l4_bn', nn.BatchNorm2d(256))\n",
    "model.add_module('l4_relu', nn.ReLU())\n",
    "model.add_module('l4_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l4_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l5_flatten', Flatten())\n",
    "\n",
    "model.add_module('l6_linear', nn.Linear(1024, 512))\n",
    "model.add_module('l6_bn', nn.BatchNorm1d(512))\n",
    "model.add_module('l6_relu', nn.ReLU())\n",
    "model.add_module('l6_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l7_linear', nn.Linear(512, 256))\n",
    "model.add_module('l7_bn', nn.BatchNorm1d(256))\n",
    "model.add_module('l7_relu', nn.ReLU())\n",
    "model.add_module('l7_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l8_linear', nn.Linear(256, 128))\n",
    "model.add_module('l8_bn', nn.BatchNorm1d(128))\n",
    "model.add_module('l8_relu', nn.ReLU())\n",
    "model.add_module('l8_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 251.582s\n",
      "  training loss (in-iteration): \t1.479386\n",
      "  training accuracy: \t\t\t58.77 %\n",
      "  validation accuracy: \t\t\t58.12 %\n",
      "Epoch 2 of 20 took 251.827s\n",
      "  training loss (in-iteration): \t1.129340\n",
      "  training accuracy: \t\t\t66.49 %\n",
      "  validation accuracy: \t\t\t64.45 %\n",
      "Epoch 3 of 20 took 253.363s\n",
      "  training loss (in-iteration): \t0.959166\n",
      "  training accuracy: \t\t\t66.14 %\n",
      "  validation accuracy: \t\t\t63.40 %\n",
      "Epoch 4 of 20 took 250.936s\n",
      "  training loss (in-iteration): \t0.846651\n",
      "  training accuracy: \t\t\t76.83 %\n",
      "  validation accuracy: \t\t\t71.64 %\n",
      "Epoch 5 of 20 took 251.528s\n",
      "  training loss (in-iteration): \t0.758098\n",
      "  training accuracy: \t\t\t79.85 %\n",
      "  validation accuracy: \t\t\t72.96 %\n",
      "Epoch 6 of 20 took 250.705s\n",
      "  training loss (in-iteration): \t0.682973\n",
      "  training accuracy: \t\t\t85.24 %\n",
      "  validation accuracy: \t\t\t76.54 %\n",
      "Epoch 7 of 20 took 248.430s\n",
      "  training loss (in-iteration): \t0.626218\n",
      "  training accuracy: \t\t\t87.75 %\n",
      "  validation accuracy: \t\t\t76.90 %\n",
      "Epoch 8 of 20 took 248.815s\n",
      "  training loss (in-iteration): \t0.565461\n",
      "  training accuracy: \t\t\t90.07 %\n",
      "  validation accuracy: \t\t\t78.43 %\n",
      "Epoch 9 of 20 took 248.569s\n",
      "  training loss (in-iteration): \t0.521499\n",
      "  training accuracy: \t\t\t91.72 %\n",
      "  validation accuracy: \t\t\t78.59 %\n",
      "Epoch 10 of 20 took 252.012s\n",
      "  training loss (in-iteration): \t0.483334\n",
      "  training accuracy: \t\t\t93.23 %\n",
      "  validation accuracy: \t\t\t79.19 %\n",
      "Epoch 11 of 20 took 258.869s\n",
      "  training loss (in-iteration): \t0.452666\n",
      "  training accuracy: \t\t\t93.93 %\n",
      "  validation accuracy: \t\t\t79.01 %\n",
      "Epoch 12 of 20 took 255.784s\n",
      "  training loss (in-iteration): \t0.422129\n",
      "  training accuracy: \t\t\t94.84 %\n",
      "  validation accuracy: \t\t\t78.35 %\n",
      "Epoch 13 of 20 took 249.696s\n",
      "  training loss (in-iteration): \t0.400939\n",
      "  training accuracy: \t\t\t94.75 %\n",
      "  validation accuracy: \t\t\t78.72 %\n",
      "Epoch 14 of 20 took 249.849s\n",
      "  training loss (in-iteration): \t0.369931\n",
      "  training accuracy: \t\t\t96.15 %\n",
      "  validation accuracy: \t\t\t78.64 %\n",
      "Epoch 15 of 20 took 251.843s\n",
      "  training loss (in-iteration): \t0.341815\n",
      "  training accuracy: \t\t\t97.14 %\n",
      "  validation accuracy: \t\t\t79.31 %\n",
      "Epoch 16 of 20 took 257.473s\n",
      "  training loss (in-iteration): \t0.328027\n",
      "  training accuracy: \t\t\t97.46 %\n",
      "  validation accuracy: \t\t\t78.74 %\n",
      "Epoch 17 of 20 took 252.179s\n",
      "  training loss (in-iteration): \t0.309392\n",
      "  training accuracy: \t\t\t97.83 %\n",
      "  validation accuracy: \t\t\t79.05 %\n",
      "Epoch 18 of 20 took 255.666s\n",
      "  training loss (in-iteration): \t0.291721\n",
      "  training accuracy: \t\t\t98.42 %\n",
      "  validation accuracy: \t\t\t79.19 %\n",
      "Epoch 19 of 20 took 255.817s\n",
      "  training loss (in-iteration): \t0.281975\n",
      "  training accuracy: \t\t\t98.39 %\n",
      "  validation accuracy: \t\t\t77.89 %\n",
      "Epoch 20 of 20 took 249.362s\n",
      "  training loss (in-iteration): \t0.270372\n",
      "  training accuracy: \t\t\t98.34 %\n",
      "  validation accuracy: \t\t\t79.33 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t78.61 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l1_bn', nn.BatchNorm2d(32))\n",
    "model.add_module('l1_relu', nn.ReLU())\n",
    "model.add_module('l1_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l1_dropout', nn.Dropout2d(0.3))\n",
    "\n",
    "model.add_module('l2_conv', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l2_bn', nn.BatchNorm2d(64))\n",
    "model.add_module('l2_relu', nn.ReLU())\n",
    "model.add_module('l2_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l2_dropout', nn.Dropout2d(0.3))\n",
    "\n",
    "model.add_module('l3_conv', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l3_bn', nn.BatchNorm2d(128))\n",
    "model.add_module('l3_relu', nn.ReLU())\n",
    "model.add_module('l3_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l3_dropout', nn.Dropout2d(0.3))\n",
    "\n",
    "model.add_module('l4_conv', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l4_bn', nn.BatchNorm2d(256))\n",
    "model.add_module('l4_relu', nn.ReLU())\n",
    "model.add_module('l4_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l4_dropout', nn.Dropout(0.2))\n",
    "\n",
    "model.add_module('l5_flatten', Flatten())\n",
    "\n",
    "model.add_module('l6_linear', nn.Linear(1024, 512))\n",
    "model.add_module('l6_bn', nn.BatchNorm1d(512))\n",
    "model.add_module('l6_relu', nn.ReLU())\n",
    "model.add_module('l6_dropout', nn.Dropout(0.3))\n",
    "\n",
    "model.add_module('l7_linear', nn.Linear(512, 256))\n",
    "model.add_module('l7_bn', nn.BatchNorm1d(256))\n",
    "model.add_module('l7_relu', nn.ReLU())\n",
    "model.add_module('l7_dropout', nn.Dropout(0.3))\n",
    "\n",
    "model.add_module('l8_linear', nn.Linear(256, 128))\n",
    "model.add_module('l8_bn', nn.BatchNorm1d(128))\n",
    "model.add_module('l8_relu', nn.ReLU())\n",
    "model.add_module('l8_dropout', nn.Dropout(0.3))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 252.811s\n",
      "  training loss (in-iteration): \t1.765514\n",
      "  training accuracy: \t\t\t47.84 %\n",
      "  validation accuracy: \t\t\t47.76 %\n",
      "Epoch 2 of 20 took 254.639s\n",
      "  training loss (in-iteration): \t1.507591\n",
      "  training accuracy: \t\t\t56.28 %\n",
      "  validation accuracy: \t\t\t55.14 %\n",
      "Epoch 3 of 20 took 255.884s\n",
      "  training loss (in-iteration): \t1.367354\n",
      "  training accuracy: \t\t\t59.22 %\n",
      "  validation accuracy: \t\t\t57.45 %\n",
      "Epoch 4 of 20 took 249.273s\n",
      "  training loss (in-iteration): \t1.264435\n",
      "  training accuracy: \t\t\t66.00 %\n",
      "  validation accuracy: \t\t\t63.53 %\n",
      "Epoch 5 of 20 took 255.538s\n",
      "  training loss (in-iteration): \t1.181103\n",
      "  training accuracy: \t\t\t68.72 %\n",
      "  validation accuracy: \t\t\t65.47 %\n",
      "Epoch 6 of 20 took 250.049s\n",
      "  training loss (in-iteration): \t1.115304\n",
      "  training accuracy: \t\t\t69.08 %\n",
      "  validation accuracy: \t\t\t66.40 %\n",
      "Epoch 7 of 20 took 252.626s\n",
      "  training loss (in-iteration): \t1.066446\n",
      "  training accuracy: \t\t\t73.22 %\n",
      "  validation accuracy: \t\t\t69.56 %\n",
      "Epoch 8 of 20 took 250.414s\n",
      "  training loss (in-iteration): \t1.025627\n",
      "  training accuracy: \t\t\t73.87 %\n",
      "  validation accuracy: \t\t\t69.96 %\n",
      "Epoch 9 of 20 took 250.034s\n",
      "  training loss (in-iteration): \t0.995470\n",
      "  training accuracy: \t\t\t76.30 %\n",
      "  validation accuracy: \t\t\t71.52 %\n",
      "Epoch 10 of 20 took 253.646s\n",
      "  training loss (in-iteration): \t0.963652\n",
      "  training accuracy: \t\t\t78.56 %\n",
      "  validation accuracy: \t\t\t73.50 %\n",
      "Epoch 11 of 20 took 247.276s\n",
      "  training loss (in-iteration): \t0.935970\n",
      "  training accuracy: \t\t\t77.57 %\n",
      "  validation accuracy: \t\t\t71.82 %\n",
      "Epoch 12 of 20 took 246.772s\n",
      "  training loss (in-iteration): \t0.903149\n",
      "  training accuracy: \t\t\t80.53 %\n",
      "  validation accuracy: \t\t\t74.67 %\n",
      "Epoch 13 of 20 took 252.206s\n",
      "  training loss (in-iteration): \t0.889325\n",
      "  training accuracy: \t\t\t80.96 %\n",
      "  validation accuracy: \t\t\t74.04 %\n",
      "Epoch 14 of 20 took 251.715s\n",
      "  training loss (in-iteration): \t0.870872\n",
      "  training accuracy: \t\t\t82.22 %\n",
      "  validation accuracy: \t\t\t75.53 %\n",
      "Epoch 15 of 20 took 247.803s\n",
      "  training loss (in-iteration): \t0.849551\n",
      "  training accuracy: \t\t\t79.65 %\n",
      "  validation accuracy: \t\t\t73.08 %\n",
      "Epoch 16 of 20 took 249.880s\n",
      "  training loss (in-iteration): \t0.826595\n",
      "  training accuracy: \t\t\t80.86 %\n",
      "  validation accuracy: \t\t\t73.67 %\n",
      "Epoch 17 of 20 took 248.124s\n",
      "  training loss (in-iteration): \t0.820763\n",
      "  training accuracy: \t\t\t84.40 %\n",
      "  validation accuracy: \t\t\t76.86 %\n",
      "Epoch 18 of 20 took 246.979s\n",
      "  training loss (in-iteration): \t0.800311\n",
      "  training accuracy: \t\t\t83.17 %\n",
      "  validation accuracy: \t\t\t75.56 %\n",
      "Epoch 19 of 20 took 249.136s\n",
      "  training loss (in-iteration): \t0.792086\n",
      "  training accuracy: \t\t\t85.51 %\n",
      "  validation accuracy: \t\t\t76.65 %\n",
      "Epoch 20 of 20 took 246.703s\n",
      "  training loss (in-iteration): \t0.774408\n",
      "  training accuracy: \t\t\t85.87 %\n",
      "  validation accuracy: \t\t\t77.17 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t76.42 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('l1_conv', nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l1_bn', nn.BatchNorm2d(16))\n",
    "model.add_module('l1_relu', nn.ReLU())\n",
    "model.add_module('l1_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l1_dropout', nn.Dropout2d(0.1))\n",
    "\n",
    "model.add_module('l2_conv', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l2_bn', nn.BatchNorm2d(32))\n",
    "model.add_module('l2_relu', nn.ReLU())\n",
    "model.add_module('l2_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l2_dropout', nn.Dropout2d(0.1))\n",
    "\n",
    "model.add_module('l3_conv', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l3_bn', nn.BatchNorm2d(64))\n",
    "model.add_module('l3_relu', nn.ReLU())\n",
    "model.add_module('l3_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l3_dropout', nn.Dropout2d(0.1))\n",
    "\n",
    "model.add_module('l4_conv', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=(1,1)))\n",
    "model.add_module('l4_bn', nn.BatchNorm2d(128))\n",
    "model.add_module('l4_relu', nn.ReLU())\n",
    "model.add_module('l4_pool', nn.MaxPool2d((2,2)))\n",
    "model.add_module('l4_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l5_flatten', Flatten())\n",
    "\n",
    "model.add_module('l6_linear', nn.Linear(512, 256))\n",
    "model.add_module('l6_bn', nn.BatchNorm1d(256))\n",
    "model.add_module('l6_relu', nn.ReLU())\n",
    "model.add_module('l6_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l7_linear', nn.Linear(256, 128))\n",
    "model.add_module('l7_bn', nn.BatchNorm1d(128))\n",
    "model.add_module('l7_relu', nn.ReLU())\n",
    "model.add_module('l7_dropout', nn.Dropout(0.1))\n",
    "\n",
    "model.add_module('l_end', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20 took 119.636s\n",
      "  training loss (in-iteration): \t1.535589\n",
      "  training accuracy: \t\t\t56.97 %\n",
      "  validation accuracy: \t\t\t56.11 %\n",
      "Epoch 2 of 20 took 119.444s\n",
      "  training loss (in-iteration): \t1.218669\n",
      "  training accuracy: \t\t\t67.20 %\n",
      "  validation accuracy: \t\t\t64.98 %\n",
      "Epoch 3 of 20 took 119.910s\n",
      "  training loss (in-iteration): \t1.075655\n",
      "  training accuracy: \t\t\t70.42 %\n",
      "  validation accuracy: \t\t\t67.44 %\n",
      "Epoch 4 of 20 took 120.112s\n",
      "  training loss (in-iteration): \t0.977414\n",
      "  training accuracy: \t\t\t73.53 %\n",
      "  validation accuracy: \t\t\t70.20 %\n",
      "Epoch 5 of 20 took 120.476s\n",
      "  training loss (in-iteration): \t0.912952\n",
      "  training accuracy: \t\t\t74.21 %\n",
      "  validation accuracy: \t\t\t69.55 %\n",
      "Epoch 6 of 20 took 120.270s\n",
      "  training loss (in-iteration): \t0.865610\n",
      "  training accuracy: \t\t\t77.85 %\n",
      "  validation accuracy: \t\t\t71.73 %\n",
      "Epoch 7 of 20 took 120.794s\n",
      "  training loss (in-iteration): \t0.822262\n",
      "  training accuracy: \t\t\t79.93 %\n",
      "  validation accuracy: \t\t\t72.82 %\n",
      "Epoch 8 of 20 took 120.469s\n",
      "  training loss (in-iteration): \t0.790053\n",
      "  training accuracy: \t\t\t81.64 %\n",
      "  validation accuracy: \t\t\t73.66 %\n",
      "Epoch 9 of 20 took 120.656s\n",
      "  training loss (in-iteration): \t0.748591\n",
      "  training accuracy: \t\t\t82.66 %\n",
      "  validation accuracy: \t\t\t74.44 %\n",
      "Epoch 10 of 20 took 120.465s\n",
      "  training loss (in-iteration): \t0.729787\n",
      "  training accuracy: \t\t\t83.73 %\n",
      "  validation accuracy: \t\t\t74.77 %\n",
      "Epoch 11 of 20 took 120.763s\n",
      "  training loss (in-iteration): \t0.699690\n",
      "  training accuracy: \t\t\t85.58 %\n",
      "  validation accuracy: \t\t\t75.29 %\n",
      "Epoch 12 of 20 took 120.747s\n",
      "  training loss (in-iteration): \t0.681748\n",
      "  training accuracy: \t\t\t84.90 %\n",
      "  validation accuracy: \t\t\t74.18 %\n",
      "Epoch 13 of 20 took 120.680s\n",
      "  training loss (in-iteration): \t0.664389\n",
      "  training accuracy: \t\t\t85.56 %\n",
      "  validation accuracy: \t\t\t74.76 %\n",
      "Epoch 14 of 20 took 121.037s\n",
      "  training loss (in-iteration): \t0.642499\n",
      "  training accuracy: \t\t\t87.14 %\n",
      "  validation accuracy: \t\t\t75.07 %\n",
      "Epoch 15 of 20 took 120.988s\n",
      "  training loss (in-iteration): \t0.627084\n",
      "  training accuracy: \t\t\t87.56 %\n",
      "  validation accuracy: \t\t\t75.34 %\n",
      "Epoch 16 of 20 took 120.852s\n",
      "  training loss (in-iteration): \t0.610649\n",
      "  training accuracy: \t\t\t88.71 %\n",
      "  validation accuracy: \t\t\t75.45 %\n",
      "Epoch 17 of 20 took 120.790s\n",
      "  training loss (in-iteration): \t0.597417\n",
      "  training accuracy: \t\t\t89.07 %\n",
      "  validation accuracy: \t\t\t75.86 %\n",
      "Epoch 18 of 20 took 120.623s\n",
      "  training loss (in-iteration): \t0.582182\n",
      "  training accuracy: \t\t\t90.48 %\n",
      "  validation accuracy: \t\t\t76.77 %\n",
      "Epoch 19 of 20 took 120.525s\n",
      "  training loss (in-iteration): \t0.571142\n",
      "  training accuracy: \t\t\t89.78 %\n",
      "  validation accuracy: \t\t\t75.64 %\n",
      "Epoch 20 of 20 took 120.452s\n",
      "  training loss (in-iteration): \t0.554955\n",
      "  training accuracy: \t\t\t91.25 %\n",
      "  validation accuracy: \t\t\t76.50 %\n"
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t76.08 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Report\n",
    "\n",
    "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
    "* the idea;\n",
    "* brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method and, again, why?\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "\n",
    "There is no need to write strict mathematical proofs (unless you want to).\n",
    " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
    " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
    " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `Chikunov Anton`, and here's my story\n",
    "\n",
    "A long time ago in a galaxy far far away, when it was still more than an hour before the deadline, i got an idea:\n",
    "\n",
    "* First of all, I tried simple linear model and got $\\approx$ 36%\n",
    "* Playing with only linear layers didn't give any real boost so I added conv layer with pool and got 57%-58%\n",
    "* Then I added BN after all base layers and dropout before end layer\n",
    "* Also, power of 2 is power\n",
    "* I tried to play with different combination of layer orders and realazied two pwoerfull patterns of combination\n",
    "    * Conv Layer template:\n",
    "        * Conv\n",
    "        * BN\n",
    "        * RELU\n",
    "        * Pool\n",
    "        * (There is also Dropout but in power conf I get 79.67 without it)\n",
    "    * Linear Layer template:\n",
    "        * Linear\n",
    "        * BN\n",
    "        * RELU\n",
    "        * Dropout\n",
    "* After that i got %79.67 and it was maximum of my warlock power. =( \n",
    "* Any other values only had decreased this power. This is realy disgusting. (\"What a story, Mark\")\n",
    "\n",
    "BTW, Layers, such as conv, pools, etc, are typicaly used for image classification. Dropout are used to avoid overfitting.\n",
    "\n",
    "My monster:\n",
    "```\n",
    "Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), padding=(1,1))\n",
    "BatchNorm2d(32)\n",
    "ReLU()\n",
    "MaxPool2d((2,2))\n",
    "\n",
    "Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), padding=(1,1))\n",
    "BatchNorm2d(64)\n",
    "ReLU()\n",
    "MaxPool2d((2,2))\n",
    "\n",
    "Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), padding=(1,1))\n",
    "BatchNorm2d(128)\n",
    "ReLU()\n",
    "MaxPool2d((2,2))\n",
    "\n",
    "Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), padding=(1,1))\n",
    "BatchNorm2d(256)\n",
    "ReLU()\n",
    "MaxPool2d((2,2))\n",
    "\n",
    "Dropout(0.2)\n",
    "Flatten()\n",
    "\n",
    "Linear(1024, 512)\n",
    "BatchNorm1d(512)\n",
    "ReLU()\n",
    "Dropout(0.2)\n",
    "\n",
    "Linear(512, 256)\n",
    "BatchNorm1d(256)\n",
    "ReLU()\n",
    "Dropout(0.2)\n",
    "\n",
    "Linear(256, 128)\n",
    "BatchNorm1d(128)\n",
    "ReLU()\n",
    "Dropout(0.2)\n",
    "\n",
    "Linear(128, 10)\n",
    "```\n",
    "\n",
    "Trainig method: \n",
    "* cross_entropy as loss\n",
    "* iterated over the epochs with minibatches\n",
    "* Adam optimizer (with 0.003 as default)\n",
    "\n",
    "training accuracy:   99.12 %\n",
    "\n",
    "validation accuracy: 79.69 %\n",
    "\n",
    "test accuracy:\t\t 79.67 %\n",
    "\n",
    "[an optional afterword and mortal curses on assignment authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
